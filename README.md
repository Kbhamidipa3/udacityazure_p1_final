# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree. In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model. This model is then compared to an Azure AutoML run.

## Summary
**The bankmarketing_train.csv dataset contains various metrics about potential customers that could eventually be utilizing the services of the bank. The objective of the project is to determine who is likely to end up becoming a customer based on the information available from the database.**

**Both Hyperparameter Tuning with HyperDrive and Automated ML methods were evaluated. While the difference was relatively smaller, the Automated ML method showed the best performance between the two with a “Best Accuracy” of 0.91709.**

## Scikit-learn Pipeline
**The high-level Scikit-learn Pipeline is shown in Figure 1:**

![GitHub Logo](/images/Figure_1.png)
Format: ![Alt Text](url)
### train.py module:
There are several steps involved in setting up and running the trained model, which is done in train.py for the HyperDrive model.
* Tabular data is first accessed from the following link and dataset is created:
https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv

* First data is converted to dataframe using Pandas and missing values are dropped.

* Then the data is cleaned to get it ready for training the model. This involves translating categorical data into numerical data before fitting a machine learning model. 
* One method used is one hot encoding where each categories under a given parameter is split into it’s own column and assigned values ‘0’ or ‘1’ depending on whether an item doesn’t belong or belong under the given category respectively. Then all the individual columns are added back.

* Another method used to generate numerical data from categorical values is using key-value pairs from Dictionaries.


* Other columns that have binary values like “married” or “not married” are assigned values 1 and 0 respectively.

* A separate column is created for label values that we want to predict by popping out it from the dataframe.


* Then the data is split into train and test values using a certain split such that more data is assigned under “train” data to get accurate model fits. In the following code, 67% of the data is used for training and remaining 33% is used for testing. Setting random_state (42 in the following example) to a specified value can ensure that the data will return same results after each execution. 

* Logistic Regression model is used to fit the train data. And two parameters were chosen – Inverse of Regularization Strength (denoted by C) and Maximum Iterations (denoted by max_iter). 

 
* The accuracy of the model is then determined using the score method.

 ### Hyperparameter Tuning 
**As mentioned in the previous section, Hyperparameter tuning method is used to tune the two parameters defined in train.py - Inverse of Regularization Strength (denoted by C) and Maximum Iterations (denoted by max_iter). The former parameter “C” helps to avoid overfitting. The parameter max_iter dictates the maximum number of iterations for the regression model. These parameters are randomly sampled using the RandomParameterSampling method to understand the impact of the parameters on the output prediction accuracy.**

**Specifying an early stopping policy improves computational efficiency by terminating poorly performing runs. BanditPolicy was chosen as the early stopping policy in this project with slack factor and evaluation interval as the parameters. Every run is compared to the Best performing run at the end of the specified evaluation interval and in combination with the slack factor (allowed slack value compared to the best performing model) determines whether the run should continue or terminate. **

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
