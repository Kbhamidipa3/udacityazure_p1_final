{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-127887\n",
      "Azure region: southcentralus\n",
      "Subscription id: de47103e-2da6-4f5e-88fc-d18b27fd249b\n",
      "Resource group: aml-quickstarts-127887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from azureml.core.run import Run\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core import Workspace, Dataset\n",
    "from azureml.core import Workspace,ScriptRunConfig,Experiment, Run\n",
    "\n",
    "ws = Workspace(subscription_id=\"de47103e-2da6-4f5e-88fc-d18b27fd249b\",\n",
    "                  resource_group=\"aml-quickstarts-127887\",\n",
    "                  workspace_name=\"quick-starts-ws-127887\")\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project-hp\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "\n",
    "   # Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "   # Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                              max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - You have specified to install packages in your run. Note that you have overridden Azure ML's installation of the following packages: ['joblib']. We cannot guarantee image build will succeed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, normal, choice\n",
    "import os,shutil\n",
    "\n",
    "# Specify parameter sampler\n",
    "ps = RandomParameterSampling( {\n",
    "        '--C': choice(0,0.25,0.5,1),\n",
    "        '--max_iter': choice(10,50,500,1000)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Specify a Policy\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "script_folder = \"./training\"    \n",
    "    \n",
    "# Reference: lesson 6.3: copying the training file into the script folder\n",
    "shutil.copy('./train.py', script_folder)\n",
    "    \n",
    "script_params={\n",
    "    '--datastore-dir': ws.get_default_datastore().as_mount(),\n",
    "}\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "sk_estimator = SKLearn(source_directory='training', \n",
    "                     script_params=script_params,\n",
    "                    compute_target=cpu_cluster,\n",
    "                    entry_script='train.py',\n",
    "                    pip_packages=['joblib']\n",
    "                   )\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator = sk_estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"Accuracy\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 20,\n",
    "                                            max_concurrent_runs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING - If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eae19c377c4632b619f478aa7987a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/udacity-project-hp/runs/HD_419f0dd0-f0db-467b-8899-160ba99e417e?wsid=/subscriptions/de47103e-2da6-4f5e-88fc-d18b27fd249b/resourcegroups/aml-quickstarts-127887/workspaces/quick-starts-ws-127887\", \"run_id\": \"HD_419f0dd0-f0db-467b-8899-160ba99e417e\", \"run_properties\": {\"run_id\": \"HD_419f0dd0-f0db-467b-8899-160ba99e417e\", \"created_utc\": \"2020-11-25T17:00:47.157651Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"84ab50ba-0992-48ee-a910-fef98ca3f168\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"20\", \"max_total_jobs\": \"20\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 2, \\\"delay_evaluation\\\": 0, \\\"slack_factor\\\": 0.15}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 2, \\\"delay_evaluation\\\": 0, \\\"slack_factor\\\": 0.15}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0, 0.25, 0.5, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 50, 500, 1000]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0, 0.25, 0.5, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 50, 500, 1000]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/de47103e-2da6-4f5e-88fc-d18b27fd249b/resourceGroups/aml-quickstarts-127887/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-127887/experiments/udacity-project-hp\\\", \\\"SubscriptionId\\\": \\\"de47103e-2da6-4f5e-88fc-d18b27fd249b\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-127887\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-127887\\\", \\\"ExperimentName\\\": \\\"udacity-project-hp\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [\\\"--datastore-dir\\\", \\\"$AZUREML_DATAREFERENCE_workspaceblobstore\\\"], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"joblib\\\", \\\"azureml-defaults\\\", \\\"scikit-learn==0.20.3\\\", \\\"scipy==1.2.1\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"workspaceblobstore\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": null, \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"84ab50ba-0992-48ee-a910-fef98ca3f168\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"2db76ed7-12c6-4179-bdd7-371b812f4996\\\", \\\"amlClientSessionId\\\": \\\"c9d57fb6-efc8-485c-abb9-8b8ece6cd523\\\", \\\"subscriptionId\\\": \\\"de47103e-2da6-4f5e-88fc-d18b27fd249b\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/de47103e-2da6-4f5e-88fc-d18b27fd249b/resourceGroups/aml-quickstarts-127887/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-127887/experiments/udacity-project-hp\\\", \\\"SubscriptionId\\\": \\\"de47103e-2da6-4f5e-88fc-d18b27fd249b\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-127887\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-127887\\\", \\\"ExperimentName\\\": \\\"udacity-project-hp\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [\\\"--datastore-dir\\\", \\\"$AZUREML_DATAREFERENCE_workspaceblobstore\\\"], \\\"target\\\": \\\"cpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"joblib\\\", \\\"azureml-defaults\\\", \\\"scikit-learn==0.20.3\\\", \\\"scipy==1.2.1\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"workspaceblobstore\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": null, \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"84ab50ba-0992-48ee-a910-fef98ca3f168\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"2db76ed7-12c6-4179-bdd7-371b812f4996\\\", \\\"amlClientSessionId\\\": \\\"c9d57fb6-efc8-485c-abb9-8b8ece6cd523\\\", \\\"subscriptionId\\\": \\\"de47103e-2da6-4f5e-88fc-d18b27fd249b\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 20, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2020-11-25T17:00:47.827728\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-11-25T17:00:47.827728\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"0d5c71a95369f1234068c87be85a85d4509b78080831968a1655e69f401c7fec\\\"\", \"progress_metadata_digest\": \"\\\"0d5c71a95369f1234068c87be85a85d4509b78080831968a1655e69f401c7fec\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2020-11-25T17:00:47.827728\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-11-25T17:00:47.827728\\\"\", \"_aml_system_HD_419f0dd0-f0db-467b-8899-160ba99e417e_0\": \"{\\\"--C\\\": 0.5, \\\"--max_iter\\\": 500}\", \"HD_419f0dd0-f0db-467b-8899-160ba99e417e_0\": \"{\\\"--C\\\": 0.5, \\\"--max_iter\\\": 500}\", \"_aml_system_HD_419f0dd0-f0db-467b-8899-160ba99e417e_1\": \"{\\\"--C\\\": 0.5, \\\"--max_iter\\\": 1000}\", \"HD_419f0dd0-f0db-467b-8899-160ba99e417e_1\": \"{\\\"--C\\\": 0.5, \\\"--max_iter\\\": 1000}\", \"_aml_system_HD_419f0dd0-f0db-467b-8899-160ba99e417e_2\": \"{\\\"--C\\\": 0.5, \\\"--max_iter\\\": 10}\", \"HD_419f0dd0-f0db-467b-8899-160ba99e417e_2\": \"{\\\"--C\\\": 0.5, \\\"--max_iter\\\": 10}\", \"_aml_system_HD_419f0dd0-f0db-467b-8899-160ba99e417e_3\": \"{\\\"--C\\\": 0.25, \\\"--max_iter\\\": 50}\", \"HD_419f0dd0-f0db-467b-8899-160ba99e417e_3\": \"{\\\"--C\\\": 0.25, \\\"--max_iter\\\": 50}\", \"_aml_system_environment_preparation_status\": \"PREPARING\", \"environment_preparation_status\": \"PREPARING\", \"_aml_system_prepare_run_id\": \"HD_419f0dd0-f0db-467b-8899-160ba99e417e_preparation\", \"prepare_run_id\": \"HD_419f0dd0-f0db-467b-8899-160ba99e417e_preparation\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg127887.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_419f0dd0-f0db-467b-8899-160ba99e417e/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=uQy83RmRZaxwIB0ldf1OtgNmQNl7Jbakw5DR5KsfEyQ%3D&st=2020-11-25T16%3A50%3A52Z&se=2020-11-26T01%3A00%3A52Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:01:28\", \"hyper_parameters\": {\"--C\": [\"choice\", [[0, 0.25, 0.5, 1]]], \"--max_iter\": [\"choice\", [[10, 50, 500, 1000]]]}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2020-11-25T17:00:47.941693][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2020-11-25T17:00:48.121100][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-25T17:00:47.447033][API][INFO]Experiment created\\r\\n[2020-11-25T17:00:49.7074595Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.18.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "hd_run = exp.submit(hyperdrive_run_config)\n",
    "RunDetails(Run(exp, hd_run.id)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Run Id:  HD_419f0dd0-f0db-467b-8899-160ba99e417e_3\n",
      "\n",
      " Accuracy: 0.910152657715652\n",
      "\n",
      " learning rate: 0.25\n",
      "\n",
      " keep probability: 50\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "best_run = hd_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['Accuracy'])\n",
    "print('\\n learning rate:',parameter_values[3])\n",
    "print('\\n keep probability:',parameter_values[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "from azureml.core import Dataset\n",
    "exp_automl = Experiment(workspace=ws, name=\"udacity-project-automl\")\n",
    "config = ScriptRunConfig(source_directory='training', script='train.py', compute_target='cpu-cluster')\n",
    "data = \"https://udacitystorage.blob.core.windows.net/udacity/bankmarketing_train.csv\"\n",
    "ds = Dataset.Tabular.from_delimited_files(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading data_train/data_train.csv\n",
      "Uploaded data_train/data_train.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "from train import clean_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "x, y = clean_data(ds)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "data_train = pd.concat([x_train,y_train], axis=1)\n",
    "\n",
    "os.makedirs('data_train', exist_ok=True)\n",
    "\n",
    "local_path = './data_train/data_train.csv'\n",
    "data_train.to_csv(local_path)\n",
    "\n",
    "# upload the local file to a datastore on the cloud\n",
    "workspace = Workspace(ws.subscription_id, ws.resource_group, ws.name)\n",
    "\n",
    "# get the datastore to upload prepared data\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "# upload the local file from src_dir to the target_path in datastore\n",
    "datastore.upload(src_dir='data_train', target_path='data_train')\n",
    "\n",
    "# create a dataset referencing the cloud location\n",
    "data_train = Dataset.Tabular.from_delimited_files(path = [(datastore, ('data_train/data_train.csv'))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data=data_train,\n",
    "    label_column_name=\"y\",\n",
    "    n_cross_validations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_efb70987-acd3-4ea7-bcc3-5ab5b2370e0c\n",
      "\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed fit featurizers and featurizing the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|2764                             |1                                |24712                                 |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:27       0.9142    0.9142\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:30       0.9140    0.9142\n",
      "         2   MaxAbsScaler RandomForest                      0:00:27       0.8973    0.9142\n",
      "         3   MaxAbsScaler RandomForest                      0:00:24       0.8882    0.9142\n",
      "         4   MaxAbsScaler SGD                               0:00:23       0.8536    0.9142\n",
      "         5   MaxAbsScaler SGD                               0:00:28       0.9062    0.9142\n",
      "         6   MaxAbsScaler ExtremeRandomTrees                0:00:32       0.8986    0.9142\n",
      "         7   MaxAbsScaler ExtremeRandomTrees                0:00:33       0.8998    0.9142\n",
      "         8   MaxAbsScaler ExtremeRandomTrees                0:00:26       0.8994    0.9142\n",
      "         9   MaxAbsScaler ExtremeRandomTrees                0:00:25       0.7460    0.9142\n",
      "        10   MaxAbsScaler SGD                               0:00:27       0.9025    0.9142\n",
      "        11   MaxAbsScaler SGD                               0:00:21       0.9019    0.9142\n",
      "        12   MaxAbsScaler RandomForest                      0:00:28       0.8894    0.9142\n",
      "        13   StandardScalerWrapper ExtremeRandomTrees       0:00:26       0.8882    0.9142\n",
      "        14   MaxAbsScaler RandomForest                      0:00:29       0.7603    0.9142\n",
      "        15   MaxAbsScaler SGD                               0:00:29       0.8470    0.9142\n",
      "        16   MaxAbsScaler RandomForest                      0:00:24       0.8882    0.9142\n",
      "        17   MaxAbsScaler ExtremeRandomTrees                0:00:25       0.8992    0.9142\n",
      "        18   SparseNormalizer ExtremeRandomTrees            0:00:27       0.7262    0.9142\n",
      "        19   MaxAbsScaler SGD                               0:00:22       0.9070    0.9142\n",
      "        20   MaxAbsScaler ExtremeRandomTrees                0:00:26       0.7413    0.9142\n",
      "        21   MaxAbsScaler RandomForest                      0:00:29       0.7690    0.9142\n",
      "        22   MaxAbsScaler LightGBM                          0:00:35       0.9050    0.9142\n",
      "        23   MaxAbsScaler RandomForest                      0:00:25       0.8882    0.9142\n",
      "        24   MaxAbsScaler LightGBM                          0:00:31       0.9092    0.9142\n",
      "        25   MaxAbsScaler LightGBM                          0:00:22       0.8882    0.9142\n",
      "        26   StandardScalerWrapper XGBoostClassifier        0:00:23       0.9044    0.9142\n",
      "        27   MaxAbsScaler ExtremeRandomTrees                0:00:28       0.8998    0.9142\n",
      "        28   MaxAbsScaler LightGBM                          0:00:29       0.9077    0.9142\n",
      "        29   SparseNormalizer XGBoostClassifier             0:00:34       0.9109    0.9142\n",
      "        30   MaxAbsScaler LightGBM                          0:00:23       0.8882    0.9142\n",
      "        31   SparseNormalizer XGBoostClassifier             0:01:09       0.9092    0.9142\n",
      "        32   StandardScalerWrapper LightGBM                 0:00:35       0.9028    0.9142\n",
      "        33   SparseNormalizer ExtremeRandomTrees            0:00:42       0.8882    0.9142\n",
      "        34   StandardScalerWrapper XGBoostClassifier        0:00:26       0.9113    0.9142\n",
      "        35   MaxAbsScaler LightGBM                          0:00:25       0.8960    0.9142\n",
      "        36   StandardScalerWrapper LightGBM                 0:00:34       0.9022    0.9142\n",
      "        37   StandardScalerWrapper LightGBM                 0:00:29       0.8952    0.9142\n",
      "        38   SparseNormalizer XGBoostClassifier             0:00:59       0.9107    0.9142\n",
      "        39   StandardScalerWrapper ExtremeRandomTrees       0:00:34       0.8998    0.9142\n",
      "        40   MaxAbsScaler LightGBM                          0:00:23       0.8882    0.9142\n",
      "        41   StandardScalerWrapper LightGBM                 0:00:25       0.9056    0.9142\n",
      "        42   SparseNormalizer XGBoostClassifier             0:00:30       0.9082    0.9142\n",
      "        43   MaxAbsScaler LightGBM                          0:00:23       0.9020    0.9142\n",
      "        44   MaxAbsScaler ExtremeRandomTrees                0:00:31       0.8882    0.9142\n",
      "        45   MaxAbsScaler LightGBM                          0:00:23       0.9058    0.9142\n",
      "        46   StandardScalerWrapper ExtremeRandomTrees       0:00:32       0.8996    0.9142\n",
      "        47   MaxAbsScaler LightGBM                          0:00:26       0.9060    0.9142\n",
      "        48   StandardScalerWrapper XGBoostClassifier        0:00:28       0.9021    0.9142\n",
      "        49   StandardScalerWrapper XGBoostClassifier        0:00:34       0.9131    0.9142\n",
      "        50   StandardScalerWrapper LightGBM                 0:00:37       0.9111    0.9142\n",
      "        51   MaxAbsScaler ExtremeRandomTrees                0:00:39       0.8997    0.9142\n",
      "        52   SparseNormalizer XGBoostClassifier             0:00:50       0.9107    0.9142\n",
      "        53   SparseNormalizer LightGBM                      0:00:31       0.9050    0.9142\n",
      "        54   SparseNormalizer XGBoostClassifier             0:00:31       0.9094    0.9142\n",
      "        55   StackEnsemble                                  0:01:54       0.9140    0.9171\n",
      "Stopping criteria reached at iteration 57. Ending experiment.\n",
      "****************************************************************************************************\n",
      "Current status: BestRunExplainModel. Best run model explanations started\n",
      "Current status: ModelExplanationDataSetSetup. Model explanations data setup completed\n",
      "Current status: PickSurrogateModel. Choosing LightGBM as the surrogate model for explanations\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features started\n",
      "Current status: EngineeredFeatureExplanations. Computation of engineered features completed\n",
      "Current status: RawFeaturesExplanations. Computation of raw features started\n",
      "Current status: RawFeaturesExplanations. Computation of raw features completed\n",
      "Current status: BestRunExplainModel. Best run model explanations completed\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "experiment_name = 'automl-classification'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-classification,\n",
      "Id: AutoML_efb70987-acd3-4ea7-bcc3-5ab5b2370e0c_55,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('datatransformer',\n",
      "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "                                 feature_sweeping_config=None,\n",
      "                                 feature_sweeping_timeout=None,\n",
      "                                 featurization_config=None, force_text_dnn=None,\n",
      "                                 is_cross_validation=None,\n",
      "                                 is_onnx_compatible=None, logger=None,\n",
      "                                 observer=None, task=None, working_dir=None)),\n",
      "                ('prefittedsoftvotingclassifier',...\n",
      "                                                                                                  fit_intercept=True,\n",
      "                                                                                                  l1_ratio=0.3877551020408163,\n",
      "                                                                                                  learning_rate='invscaling',\n",
      "                                                                                                  loss='log',\n",
      "                                                                                                  max_iter=1000,\n",
      "                                                                                                  n_jobs=1,\n",
      "                                                                                                  penalty='none',\n",
      "                                                                                                  power_t=0,\n",
      "                                                                                                  random_state=None,\n",
      "                                                                                                  tol=0.01))],\n",
      "                                                                     verbose=False))],\n",
      "                                               flatten_transform=None,\n",
      "                                               weights=[0.16666666666666666,\n",
      "                                                        0.25,\n",
      "                                                        0.08333333333333333,\n",
      "                                                        0.08333333333333333,\n",
      "                                                        0.16666666666666666,\n",
      "                                                        0.08333333333333333,\n",
      "                                                        0.16666666666666666]))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "best_run, fitted_model = run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n",
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
